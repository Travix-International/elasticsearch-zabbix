#!/usr/bin/env python
"""Python module to extend zabbix agent and send Elasticsearch stats to zabbix
   using zabbix_sender"""
import os
import optparse
import tempfile
import logging
import subprocess
import requests

class ElasticsearchAPI(object):
    """Class for Elasticsearch _node API"""

    def __init__(self, root_url='http://localhost:9200/', node='localhost',
                 conf='/etc/zabbix/zabbix_agentd.conf', senderhostname=None):
        self.root_url = root_url
        self.conf = conf
        self.node = node
        self.senderhostname = senderhostname
        self.metric_list = []

    def call_api(self, path='_nodes/stats'):
        """Call the API and serialize the output"""
        logging.debug("Querying Elasticsearch api [%s] on [%s]", self.root_url, path)
        url = "{0}{1}".format(self.root_url, path)
        return requests.get(url).json()

    def get_nested_values(self, values, metric_list, path):
        """Recursively iterate over the stats object and capture all leaves with
           numerical values"""

        if not isinstance(values, dict):
            if isinstance(values, (int, float)):
                metric_list.append((path, values))
            return

        for sub_node in values:
            if path:
                key = '{0}_{1}'.format(path, sub_node)
            else:
                key = '{0}'.format(sub_node)
            self.get_nested_values(values[sub_node], metric_list, key)

    def get_stats(self):
        """Recursively iterate over the stats object and capture all leaves with
           numerical values"""

        stats_list = ['breakers', 'fs', 'http', 'indices', 'jvm', 'network',
                      'os', 'process', 'thread_pool', 'transport']
        stats = self.call_api('_nodes/{0}/stats'.format(self.node)).get('nodes')

        # FIXME: Uglyiness to only collect stats for current node
        for node in stats:
            if stats[node]['name'] == self.node:
                stats = stats[node]
        # Only include the keys we want in stats dict
        stats = {k:stats[k] for k in stats_list}

        self.get_nested_values(stats, self.metric_list, None)
        tmpfile = tempfile.NamedTemporaryFile(delete=False)
        self.prepare_data(self.metric_list, tmpfile)
        tmpfile.close()
        return_code = self.send_data(tmpfile)
        os.unlink(tmpfile.name)
        return return_code

    @staticmethod
    def prepare_data(metrics_tuples, tmpfile):
        """Prepare the data in tempfile to be send to zabbix with
           zabbix_sender"""
        for metric_tuple in metrics_tuples:
            logging.debug("SENDER_DATA: - %s %s", *metric_tuple)
            tmpfile.write('- "elasticsearch.stats[{0}]" {1}\n'.format(*metric_tuple))

    def send_data(self, tmpfile):
        """Send the prepared data to zabbix with zabbix_sender"""
        cmd = 'zabbix_sender -vv -c {0} -i {1}'
        if self.senderhostname:
            cmd = cmd + " -s " + self.senderhostname
        return_code = 0
        process = subprocess.Popen(cmd.format(self.conf, tmpfile.name),
                                   shell=True, stdout=subprocess.PIPE,
                                   stderr=subprocess.PIPE)
        out, err = process.communicate()
        logging.debug("Finished sending data")
        return_code = process.wait()
        logging.info("zabbix_sender return code (%s)", return_code)
        if return_code == 1:
            logging.error(out)
            logging.error(err)
        else:
            logging.debug(out)
            logging.debug(err)
        return return_code

def main():
    """Main function"""
    parser = optparse.OptionParser()
    parser.add_option("--hostname", help="Elasticsearch API hostname",
                      default='localhost')
    parser.add_option("--port", help="Elasticsearch API port",
                      default=9200)
    parser.add_option("--protocol", help="Elasticsearch API protocol",
                      choices=['http', 'https'], default='http')
    parser.add_option("--node", help="Elasticsearch node name")
    parser.add_option("--conf", default="/etc/zabbix/zabbix_agentd.conf")
    parser.add_option("--senderhostname", default='',
                      help="Custom sender parameter for zabbix_sender")
    parser.add_option("--logfile",
                      help="Error log file",
                      default="/var/log/zabbix-agent/elasticsearch_zabbix.log")
    parser.add_option('--loglevel', choices=['ERROR', 'DEBUG', 'INFO'],
                      default='INFO')
    parser.add_option('--check', choices=['stats'], default='stats')
    (options, args) = parser.parse_args()
    logging.basicConfig(filename=options.logfile,
                        level=logging.getLevelName(options.loglevel),
                        format='%(asctime)s %(levelname)s: %(message)s')

    url = "{0}://{1}:{2}/".format(options.protocol, options.hostname,
                                  options.port)
    api = ElasticsearchAPI(root_url=url, conf=options.conf, node=options.node,
                           senderhostname=options.senderhostname)
    if not options.node:
        parser.error("Elasticsearch node name not provided")
    if options.check == 'stats':
        api.get_stats()


if __name__ == "__main__":
    main()
